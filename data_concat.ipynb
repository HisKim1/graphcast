{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Concatenator\n",
    "\n",
    "## 필요한 Data\n",
    "- surface level ERA5, precipitation 제외\n",
    "- surface level ERA5, precipitation 포함\n",
    "- pressure level ERA5\n",
    "- (optional) TOA solar incident radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import his_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset path \n",
    "ds_surface = \"testdata/2022-01-01/2022-01-01_surface.grib\"\n",
    "ds_surface_precip = \"testdata/2022-01-01/2022-01-01_tp.grib\"\n",
    "ds_surface_precip_prior = \"testdata/2022-01-01/2021-01-01_tp prior.grib\"\n",
    "ds_pressure_level = \"testdata/2022-01-01/2022-01-01_pressure level.grib\"\n",
    "ds_TOA = \"testdata/2022-01-01/2022-01-01 TOA.grib\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Surface Data w/o Precipitation\n",
    "\n",
    "precipitation 제외하고 받은 6-hrly data 전처리 하는 과정\n",
    "\n",
    "## TODO\n",
    "- dimension 이름 변경\n",
    "- 불필요한 coordinate 삭제\n",
    "- variable 이름 변경 -> 나중에 합치고 한 번에 진행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring index file 'testdata/2022-01-01/2022-01-01_surface.grib.5b7b6.idx' incompatible with GRIB file\n",
      "skipping variable: paramId==212 shortName='tisr'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hiskim1/.conda/envs/hiskim1_graphcast/lib/python3.11/site-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
      "    dict_merge(variables, coord_vars)\n",
      "  File \"/home/hiskim1/.conda/envs/hiskim1_graphcast/lib/python3.11/site-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
      "    raise DatasetBuildError(\n",
      "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='time' value=Variable(dimensions=('time',), data=array([1640995200, 1641016800, 1641038400, 1641060000, 1641081600,\n",
      "       1641103200, 1641124800, 1641146400, 1641168000, 1641189600,\n",
      "       1641211200, 1641232800, 1641254400, 1641276000, 1641297600,\n",
      "       1641319200])) new_value=Variable(dimensions=('time',), data=array([1640973600, 1641016800, 1641060000, 1641103200, 1641146400,\n",
      "       1641189600, 1641232800, 1641276000]))\n"
     ]
    }
   ],
   "source": [
    "ds1 = xr.open_dataset(ds_surface, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = ds1.drop_vars(['number', 'step', 'surface', 'valid_time'])\n",
    "ds1 = ds1.rename({\"z\" : \"geopotential_at_surface\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Precipitation Data\n",
    "\n",
    "Accumulates 6-hour precipitation into the next time step?\n",
    "or into previous step?\n",
    "\n",
    "## TODO\n",
    "- coordinate 정리\n",
    "- 강수량 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring index file 'testdata/2022-01-01/2022-01-01_tp.grib.5b7b6.idx' incompatible with GRIB file\n",
      "Ignoring index file 'testdata/2022-01-01/2021-01-01_tp prior.grib.5b7b6.idx' incompatible with GRIB file\n",
      "/tmp/ipykernel_1460850/3492998088.py:7: FutureWarning: updating coordinate 'new_time' with a PandasMultiIndex would leave the multi-index level coordinates ['time', 'step'] in an inconsistent state. This will raise an error in the future. Use `.drop_vars(['new_time', 'time', 'step'])` before assigning new coordinate values.\n",
      "  dataset = dataset.assign_coords(new_time=dataset.valid_time.values)\n"
     ]
    }
   ],
   "source": [
    "# 2-1. the time after\n",
    "ds2 = xr.open_dataset(ds_surface_precip, engine='cfgrib')\n",
    "prior = xr.open_dataset(ds_surface_precip_prior, engine='cfgrib')\n",
    "\n",
    "def sync_tp_coords(dataset: xr.Dataset):\n",
    "    dataset = dataset.stack(new_time=['time', 'step'])\n",
    "    dataset = dataset.assign_coords(new_time=dataset.valid_time.values)\n",
    "    dataset = dataset.rename({'new_time': 'time'})\n",
    "    dataset = dataset.drop_vars(['number', 'surface'])\n",
    "    return dataset\n",
    "\n",
    "ds2 = sync_tp_coords(ds2)\n",
    "ds2 = ds2.isel(time=slice(5,None)) #                                          <------- FIX HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1460850/3492998088.py:7: FutureWarning: updating coordinate 'new_time' with a PandasMultiIndex would leave the multi-index level coordinates ['time', 'step'] in an inconsistent state. This will raise an error in the future. Use `.drop_vars(['new_time', 'time', 'step'])` before assigning new coordinate values.\n",
      "  dataset = dataset.assign_coords(new_time=dataset.valid_time.values)\n"
     ]
    }
   ],
   "source": [
    "# 2-2. the time before\n",
    "\n",
    "prior = sync_tp_coords(prior)\n",
    "prior = prior.isel(time=slice(5,29)) #                                        <------- FIX HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-3. merge the two datasets\n",
    "\n",
    "ds2 = xr.concat([prior, ds2], dim='time')\n",
    "ds2 = ds2.sortby('time')\n",
    "\n",
    "ds2 = ds2.resample(time='6h', closed='right', label='right').sum()\n",
    "ds2 = ds2.isel(time=slice(4, 20)) #                                           <------- FIX HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pressure Level Data\n",
    "\n",
    "37 level data를 처리하는 과정. 17 level이어도 동일한 방식으로 작동하도록 최대한 해보자\n",
    "\n",
    "## TODO\n",
    "- coordinate 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring index file 'testdata/2022-01-01/2022-01-01_pressure level.grib.5b7b6.idx' incompatible with GRIB file\n"
     ]
    }
   ],
   "source": [
    "ds3 = xr.open_dataset(ds_pressure_level, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = ds3.drop_vars(['number', 'step', 'valid_time'])\n",
    "ds3 = ds3.rename({\"isobaricInhPa\" : \"level\"})\n",
    "ds3 = ds3.sortby('level', ascending=True)\n",
    "\n",
    "level = ds3.level.values\n",
    "level = level.astype(np.int32)\n",
    "\n",
    "ds3 = ds3.assign_coords(level = ('level', level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optional) 4. TOA 가공하기\n",
    "\n",
    "구글에서 만든 거랑 내가 다운받은거랑 같다면 상관 없음.\n",
    "다를 경우에는 이거 사용해야 함.\n",
    "\n",
    "$\\therefore$ $\\exists$ noise\n",
    "$\\Rightarrow$ 결과가 미묘하게 달라지지만 유의미해보이지는 않다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring index file 'testdata/2022-01-01/2022-01-01 TOA.grib.5b7b6.idx' incompatible with GRIB file\n",
      "/tmp/ipykernel_1460850/1352287803.py:5: FutureWarning: updating coordinate 'new_time' with a PandasMultiIndex would leave the multi-index level coordinates ['time', 'step'] in an inconsistent state. This will raise an error in the future. Use `.drop_vars(['new_time', 'time', 'step'])` before assigning new coordinate values.\n",
      "  ds4 = ds4.assign_coords(new_time=ds4.valid_time.values)\n"
     ]
    }
   ],
   "source": [
    "# 4th. TOA\n",
    "ds4 = xr.open_dataset(ds_TOA, engine='cfgrib')\n",
    "\n",
    "ds4 = ds4.stack(new_time=['time', 'step'])\n",
    "ds4 = ds4.assign_coords(new_time=ds4.valid_time.values)\n",
    "ds4 = ds4.rename({'new_time': 'time'})\n",
    "ds4 = ds4.drop_vars(['number', 'surface', 'valid_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 3개의 데이터셋을 하나로 합성하기\n",
    "\n",
    "*ds1*, *ds2*, *ds3*, (*ds4*)를 하나로 합치고 GC에 잘 들어가도록 다듬어주기\n",
    "\n",
    "## TODO\n",
    "- 한 장씩 합치는 게 좋을지, 여러 장 한 번에 합치는 게 좋을지 for memory efficiency\n",
    "- 합쳐서 GC에 잘 들어가는 지까지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all datasets\n",
    "ds_list = [ds1, ds2, ds3, ds4]\n",
    "\n",
    "result = xr.merge(ds_list)\n",
    "\n",
    "for ds in ds_list:\n",
    "    ds.close()\n",
    "\n",
    "result = his_utils.transform_dataset(result).copy()\n",
    "\n",
    "\n",
    "\n",
    "result = result.reindex(lat=result.lat[::-1])  #                        <------- FIX HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. 파일 명 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'testdata/ERA5_2022-01-01.nc'  #                                          <------- FIX HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Output: GC로 준비 갈 완료!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_netcdf(result_path)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# 번외: xarray.resample은 어떻게 작동하는가?\n",
    "\n",
    "| 1 | 2 | 3 | 4 | 5 | 6 | 7 | value\n",
    "\n",
    "| 0 | 1 | 2 | 3 | 4 | 5 | 6 | hr\n",
    "\n",
    "`closed=` 어느 쪽을 닫힌 구간으로 쓸 것인가 $\\Rightarrow$ 어느 쪽을 포함하고 반대쪽을 제외할까\n",
    "\n",
    "`label=` sample한 거를 어느 쪽에 할당할 것인가\n",
    "\n",
    "- case 1) `xarray.resample(\"6h\")`\n",
    "\n",
    "    1 + ... + 6을 0hr에 할당\n",
    "\n",
    "- case 2) `xarray.resample(\"6h\", closed='right', label='right')`\n",
    "\n",
    "    2 + ... + 7을 6hr에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 샘플 데이터 생성 (0시부터 23시까지)\n",
    "date_range = pd.date_range(start='2021-12-31T19:00:00.000000000', end='2022-01-05T06:00:00.000000000', freq='h')\n",
    "data = np.arange(1, 109, 1)\n",
    "ds = pd.Series(data, index=date_range)\n",
    "\n",
    "# 6시간 간격으로 리샘플링\n",
    "ds_resampled = ds.resample('6h', closed='right', label='right').sum()\n",
    "\n",
    "print(\"\\n리샘플링 결과:\")\n",
    "print(ds_resampled)\n",
    "\n",
    "# 각 리샘플링 구간의 시작과 끝 확인\n",
    "for i, value in ds_resampled.items():\n",
    "    start = i\n",
    "    end = i + pd.Timedelta(hours=5)\n",
    "    original_data = ds[start:end]\n",
    "    print(f\"\\n{i}의 리샘플링 구간:\")\n",
    "    print(f\"시작: {start}, 끝: {end}\")\n",
    "    print(\"포함된 원본 데이터:\")\n",
    "    print(original_data)\n",
    "    print(f\"합계: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiskim1_graphcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
